{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c6f002-dd07-4433-9cf7-b07472cf96c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "from twemoji.twemoji_dataset import TwemojiData\n",
    "from embert import SimpleSembert, TopKAccuracy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef074ab2-95e1-4332-b9ba-0b1dd93f4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_IDX = list(range(1711))\n",
    "TEST_IDX = list(range(1810))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89460cc-ff03-4cc2-9ebb-64c75f3a3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_dataset(model, data, k=1):\n",
    "    accuracy = 0\n",
    "    counter = 0\n",
    "    score = TopKAccuracy(k)\n",
    "    with tqdm(enumerate(data)) as tbatch:\n",
    "        for i, batch in tbatch:\n",
    "            X = batch[0]\n",
    "            y = batch[1]\n",
    "            outputs = model(X, TEST_IDX)\n",
    "            batch_accuracy = score(outputs, y)\n",
    "            accuracy += len(X) * batch_accuracy\n",
    "            counter += len(X)\n",
    "\n",
    "            tbatch.set_postfix(\n",
    "                batch_accuracy=batch_accuracy,\n",
    "                running_accuracy=accuracy / counter,\n",
    "            )\n",
    "\n",
    "    total_accuracy = accuracy / counter\n",
    "    print(f\"total accuracy is {total_accuracy}\")\n",
    "    return total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12b94d0-cee2-4870-b540-bd2179a4ae3f",
   "metadata": {},
   "source": [
    "### load prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2388204e-12e2-43bf-83e4-0b0cfe9cf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = pd.read_csv(\"twemoji/data/twemoji_prevalence.csv\")\n",
    "prevalence[\"faktor\"] = np.log(prevalence.prevalence/prevalence.prevalence.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f0fac-9b82-4039-9c08-e3e83e23a378",
   "metadata": {},
   "source": [
    "### helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69db3fa0-af7f-4233-81a9-bcc7cb96e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pretrained_path = \"trained_models/main_run/sembert_chunk51.ckpt\"\n",
    "\n",
    "model = SimpleSembert()\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(pretrained_path, map_location=device))\n",
    "print(f\"loaded pretrained params from: {pretrained_path}\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785d99f-3813-4e84-8edb-83e67e774235",
   "metadata": {},
   "source": [
    "### evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1bee14-6faf-4892-ae3a-2396ffa04953",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TwemojiData(\"balanced_train_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25bd641-5679-4918-9362-fda3ab6b48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_on_dataset(model, data, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027aff28-e3fa-4567-a16b-5925ad059351",
   "metadata": {},
   "source": [
    "#### change normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26fa6846-7927-47bd-820f-80fa2b50e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.normalize = prevalence.apply(lambda x: (int(x.emoji_ids), x.faktor), axis = 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2d26e2-6b41-4715-99c3-bf2c1fa866ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:30,  2.76s/it, batch_accuracy=0.125, running_accuracy=0.169]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y2/kn_782d959q_kshjqj842tpc0000gn/T/ipykernel_27744/2902950715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/y2/kn_782d959q_kshjqj842tpc0000gn/T/ipykernel_27744/578367652.py\u001b[0m in \u001b[0;36mevaluate_on_dataset\u001b[0;34m(model, data, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/cs224n/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/masters/Q2/cs224n/project/emoji_prediction/embert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence_ls, emoji_ids)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mX_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memoji_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_on_dataset(model, data, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84176a55-0599-4fb4-902b-3ce5b684f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Are you even joking with these right now? But it fits my theme though Late night so badâ€¦ https://t.co/EZURbZGynz',\n",
       " [1448, 371])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e7d67-d751-40d1-9fc7-9ef8a4d26551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
