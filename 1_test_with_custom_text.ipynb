{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d587ad-ed4e-4245-843b-135e3c344c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646fe3bf-336b-4d70-8c73-d2f383c890da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from twemoji.twemoji_dataset import TwemojiData, TwemojiBalancedData, TwemojiDataChunks\n",
    "from embert import Sembert, TopKAccuracy, LiteralModel, Baseline\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d05eff-7d93-4e79-b0cc-9597c9440ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TRAIN_IDX = list(range(1711))\n",
    "TEST_IDX = list(range(1810))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62a221-e041-454b-bf4e-5030db7f28dc",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d517c1-b62d-447f-888d-e01aeb248cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(balanced=False):\n",
    "    model = Sembert(dropout=0.2)\n",
    "    model = model.to(device)\n",
    "    if balanced:\n",
    "        pretrained_path = \"trained_models/balanced_sembert_dropout/balanced_sembert_dropout_chunk106.ckpt\"\n",
    "    else:\n",
    "        pretrained_path = \"trained_models/sembert_dropout/sembert_dropout_chunk77.ckpt\"\n",
    "    model.load_state_dict(torch.load(pretrained_path, map_location=device))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f27cb-68e5-44e6-b10b-8eb7f63950c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# model1 = get_model()\n",
    "# model2 = get_model(balanced=True)\n",
    "\n",
    "model1 = LiteralModel()\n",
    "model2 = Baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae07c22-c07d-49e5-8519-a897a469eb86",
   "metadata": {},
   "source": [
    "### load mapping dicts etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282566f-cb5c-470e-bfab-9e8a7ba45ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_des = pd.read_csv(\"emoji_embedding/data/processed/emoji_descriptions.csv\")\n",
    "emoji_id_char = {k: v for k, v in zip(df_des.emoji_id, df_des.emoji_char)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca30dd-cdaa-42db-b0c9-0d4b77ba584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_EMOJIS = (\n",
    "    pd.read_csv(\"twemoji/data/twemoji_prevalence.csv\")\n",
    "    .sort_values(by=\"prevalence\", ascending=False)\n",
    "    .emoji_ids.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34380bb0-9b70-45a8-8b1e-09ad48a13343",
   "metadata": {},
   "source": [
    "### create artificial custom twitter sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8d7b4-8dc3-400e-8288-71d107787b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(model, X, restriction_type=None):\n",
    "    \"\"\"Returns the adjusted output of our model. Depending on the restriction type\n",
    "    the prediction of certain emojis is set to 0.\n",
    "\n",
    "    Params:\n",
    "        - model {torch.nn.Module}: model that outputs probabilities for each emoji\n",
    "            given the list of input sentences X and emojis to be considered\n",
    "        - X {list}: list of string sentences that are to be used for prediction\n",
    "        - restriction_type {int}: determines which emoji predictions to set to 0\n",
    "                - -1 set all emojis that have been known during training to 0\n",
    "                - any other integer i: set the top i emojis (according to prevalence in)\n",
    "                    training data to zero\n",
    "    \"\"\"\n",
    "    outputs = model(X, TEST_IDX)\n",
    "    if restriction_type is not None:\n",
    "        if restriction_type > 0:\n",
    "            excluded_emojis = TOP_EMOJIS[:restriction_type]\n",
    "        else:\n",
    "            excluded_emojis = TRAIN_IDX\n",
    "        mask_idx = [int(i not in excluded_emojis) for i in TEST_IDX]\n",
    "        mask_idx = torch.tensor([mask_idx for _ in range(len(X))]).to(device)\n",
    "        outputs = outputs * mask_idx\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def get_emojis(model, sentences, top_k, emoji_id_char, restricted_type=None):\n",
    "    \"\"\"\n",
    "    Prints sentence and the model predicted normal top k prediction\n",
    "    and top k restricted predictions as specified in restricted type.\n",
    "    \"\"\"\n",
    "    predictions = get_outputs(model, sentences)\n",
    "    _, topk_emoji_ids = torch.topk(predictions, top_k, dim=-1)\n",
    "    topk_predictions = [\n",
    "        [emoji_id_char[em.item()] for em in row] for row in topk_emoji_ids\n",
    "    ]\n",
    "\n",
    "    predictions_restricted = get_outputs(model, sentences, restricted_type)\n",
    "    _, topk_emoji_ids_restricted = torch.topk(predictions_restricted, top_k, dim=-1)\n",
    "    topk_predictions_restricted = [\n",
    "        [emoji_id_char[em.item()] for em in row] for row in topk_emoji_ids_restricted\n",
    "    ]\n",
    "\n",
    "    for i, s in enumerate(sentences):\n",
    "        print(\n",
    "            s,\n",
    "            \"### normal prediction\",\n",
    "            topk_predictions[i],\n",
    "            \"### restricted prediction\",\n",
    "            topk_predictions_restricted[i],\n",
    "            \"\\n\",\n",
    "        )\n",
    "\n",
    "\n",
    "def get_proba_for_emoji(model, sentences, emoji_idx, emoji_id_char):\n",
    "    \"\"\"\n",
    "    For given sentences print the probabilities assigned by the model to particular\n",
    "    emoji: emoij_idx.\n",
    "    \"\"\"\n",
    "    predictions = get_outputs(model, sentences)\n",
    "    probas = torch.gather(\n",
    "        predictions, 1, torch.tensor([[emoji_idx] for _ in range(len(sentences))])\n",
    "    )\n",
    "    for i, s in enumerate(sentences):\n",
    "        print(\n",
    "            s,\n",
    "            f\"probability for {emoji_id_char[emoji_idx]}\",\n",
    "            probas[i].item(),\n",
    "            \"\\n\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403ff16-c8f2-4726-9ee6-be22568f0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"i like dinosaurs!\",\n",
    "    \"i like sauropod!\",\n",
    "    \"crocodiles are so awesome.\",\n",
    "    \"came back home and saw an elephant\",\n",
    "    \"i hate it when people don't text back\",\n",
    "    \"war is bad we need peace\",\n",
    "    \"second place medal looks good\",\n",
    "    \"this football game is lit\",\n",
    "    \"I am so angryyy\",\n",
    "    \"swinging an axe\",\n",
    "    \"I am a baby\",\n",
    "    \"crocodile, crocodile, crocodile\",\n",
    "    \"crocodile\",\n",
    "    \"turtle\",\n",
    "    \"I like turtles\",\n",
    "    \"I am the dragon master\",\n",
    "    \"blue whales are my favorite animals\",\n",
    "    \"penis\",\n",
    "    \"shake that ass\",\n",
    "    \"shake that booty\",\n",
    "    \"idiot\",\n",
    "    \"do you want to come over tonight?\",\n",
    "    \"it's getting a littly cold\",\n",
    "    \"he is hitting one after another basket\",\n",
    "]\n",
    "\n",
    "print(\"\\n\", \"*\" * 10, \"sembert_dropout\", \"*\" * 10, \"\\n\")\n",
    "get_emojis(model1, sentences, 5, emoji_id_char, restricted_type=40)\n",
    "print(\"\\n\", \"*\" * 10, \"balanced_sembert_dropout\", \"*\" * 10, \"\\n\")\n",
    "get_emojis(model2, sentences, 5, emoji_id_char, restricted_type=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5391ee-5e10-480a-9469-d52155f36a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_proba_for_emoji(model_balanced, sentences, 1784, emoji_id_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d780e-9aac-4120-8cc3-d0b694764ea2",
   "metadata": {},
   "source": [
    "## contrast balanced vs. non balanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c6f07-812b-432d-bf7c-19ee698ba99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ending = [\" is what I love\", \" makes me angry\", \" is such a stupid word!\"]\n",
    "test_text = (df_des.emjpd_emoji_name_og + ending[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53977e5d-30cd-4886-8713-7a102227ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_hit(\n",
    "    model, sentences, ids, top_k, emoji_id_char, restricted_type=None, batch_size=32\n",
    "):\n",
    "\n",
    "    X_ls = [sentences[i : i + batch_size] for i in range(0, len(sentences), batch_size)]\n",
    "    y_ls = [list(ids[i : i + batch_size]) for i in range(0, len(ids), batch_size)]\n",
    "\n",
    "    result = []\n",
    "    result_restricted = []\n",
    "    for i, (X, y) in enumerate(zip(X_ls, y_ls)):\n",
    "        predictions = get_outputs(model, X)\n",
    "        _, topk_emoji_ids = torch.topk(predictions, top_k, dim=-1)\n",
    "\n",
    "        predictions_restricted = get_outputs(model, X, restricted_type)\n",
    "        _, topk_emoji_ids_restricted = torch.topk(predictions_restricted, top_k, dim=-1)\n",
    "\n",
    "        min_idx = int(i * batch_size)\n",
    "        result += [y[i] in topk_emoji_ids[i] for i in range(len(X))]\n",
    "        result_restricted += [\n",
    "            y[i] in topk_emoji_ids_restricted[i] for i in range(len(X))\n",
    "        ]\n",
    "\n",
    "    return result, result_restricted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9545d-2098-429a-9e24-bf875d61cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result, result_restricted = get_topk_hit(\n",
    "    model1, test_text, range(len(test_text)), 5, emoji_id_char, restricted_type=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689a770-77d7-4971-914e-1f250f987640",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result_balanced, result_restricted_balanced = get_topk_hit(\n",
    "    model2, test_text, range(len(test_text)), 5, emoji_id_char, restricted_type=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acffc089-b357-4734-a92a-8578965c6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ls):\n",
    "    return sum(ls) / len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce54adf-e861-495e-b433-1c83636662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"normal\", get_accuracy(result))\n",
    "print(\"restricted\", get_accuracy(result_restricted))\n",
    "print(\"balanced_normal\", get_accuracy(result_balanced))\n",
    "print(\"balanced_restricted\", get_accuracy(result_restricted_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bc63e-2c16-4b89-9ac5-95f733807d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
